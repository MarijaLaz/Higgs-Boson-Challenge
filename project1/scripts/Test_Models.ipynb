{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from implementations import *\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip csv \n",
    "import zipfile\n",
    "with zipfile.ZipFile('../data/train.csv.zip') as zip_ref:\n",
    "    zip_ref.extractall(r\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,) (250000, 31) (250000,)\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "#load data\n",
    "DATA_TRAIN_PATH = '../data/train.csv' #download train data and supply path here \n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "#add constant term\n",
    "tx = np.c_[np.ones((y.shape[0], 1)), x]\n",
    "\n",
    "print(y.shape, tx.shape, ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tx.shape[1]):\n",
    "    idx = tx[:,i] > -999\n",
    "    mean = np.mean(tx[idx,i])\n",
    "    tx[idx==False,i] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Without standardization-----\n",
      "Gradient Descent, w*=[-4.67751589e+94 -5.81850804e+96 -2.22001485e+96 -3.85456979e+96\n",
      " -3.41285658e+96 -1.22781520e+95 -2.08825797e+97  5.99837695e+94\n",
      " -1.07001966e+95 -9.79576500e+95 -8.89992795e+96 -6.77484097e+94\n",
      " -6.85296718e+92 -2.28836400e+94 -1.95884542e+96  5.36483853e+92\n",
      "  2.76008615e+92 -2.29938326e+96  8.20220183e+92 -1.89642299e+93\n",
      " -2.20063783e+96  3.45121864e+92 -1.13401591e+97 -5.32557217e+94\n",
      " -4.49465766e+96  1.51167942e+92  5.03931840e+92 -2.84134005e+96\n",
      "  6.01233067e+92  1.60639686e+92 -4.64169931e+96], loss=1.1632499055428917e+200\n",
      "\n",
      "Stochastic Gradient Descent, w*=[ 4.34106574e+90  2.58870919e+92  1.65713135e+92  1.14473846e+92\n",
      "  1.00304042e+93  1.04347702e+91  1.61393571e+93 -3.56699977e+90\n",
      "  2.45966107e+90  1.00690118e+92  1.50763648e+93  9.63500365e+90\n",
      "  5.70040584e+90  1.98946588e+90  1.37249406e+92 -9.11376195e+90\n",
      "  1.26158579e+91  3.04566386e+92 -8.77719457e+90 -1.22323851e+91\n",
      "  5.81979000e+92  1.33388817e+91  1.70745758e+93  4.34288186e+90\n",
      "  1.06567109e+93 -3.51337998e+90 -2.25805084e+89  2.50390380e+92\n",
      " -5.14202253e+88 -6.87282495e+87  1.06582504e+93], loss=2.5249340332479095e+198\n",
      "\n",
      "Least Squares, w*=[-1.15432357e+00  1.82646785e-04 -7.20669300e-03 -6.45388061e-03\n",
      " -1.73089736e-05  2.32739812e-02  4.20360935e-04  2.50409912e-03\n",
      "  3.60206060e-01 -1.26384819e-03 -2.84517092e+00 -2.22720447e-01\n",
      "  9.89165262e-02  3.56759820e-01  2.85344500e+00 -6.42019571e-04\n",
      " -4.57218903e-04  2.85827859e+00 -6.80776457e-04  1.38605214e-03\n",
      "  3.15125359e-03  5.15272491e-04 -3.71558720e-04  4.27220739e-02\n",
      " -1.01225647e-03  4.70620452e-04  1.34341523e-04 -2.12423009e-03\n",
      "  1.42389535e-03 -1.78104974e-03  2.84526148e+00], loss=0.3404094521616162\n",
      "\n",
      "Ridge Regression1, w*=[-1.14969586e+00  1.82103285e-04 -7.20880929e-03 -6.44990082e-03\n",
      " -1.96630940e-05  2.30483074e-02  4.20708472e-04  2.43431944e-03\n",
      "  3.59914676e-01 -1.26452213e-03 -5.26184056e-03 -2.22775020e-01\n",
      "  9.89122981e-02  3.56477431e-01  1.35311586e-02 -6.41996153e-04\n",
      " -4.58291670e-04  1.83685972e-02 -6.80880276e-04  1.38409374e-03\n",
      "  3.15153122e-03  5.16841723e-04 -3.72031790e-04  4.14228993e-02\n",
      " -1.02930839e-03  4.71596548e-04  1.35468823e-04 -2.15425374e-03\n",
      "  1.42411312e-03 -1.77852446e-03  5.37173071e-03], loss=0.3404107160782435\n",
      "\n",
      "Logistic Ridge Regression, w*=[-2.48498000e+04 -2.98687626e+06 -2.10786467e+06 -2.05820904e+06\n",
      " -5.66240396e+05 -4.73531608e+04 -6.51259993e+06 -2.41458020e+03\n",
      " -5.82885483e+04 -4.94332467e+05 -2.67478477e+06 -4.74750142e+04\n",
      "  2.62794876e+04 -8.73013051e+03 -5.86545180e+05  1.91152510e+02\n",
      " -3.66355160e+02 -1.20968021e+06  6.21300035e+02 -5.48511605e+02\n",
      " -9.84055172e+05  1.21587099e+03 -3.99298864e+06 -1.50395700e+04\n",
      " -1.81485457e+06  1.05601620e+02  2.90291799e+02 -1.44897767e+06\n",
      "  3.47351347e+02 -2.08168422e+02 -8.78559285e+05], loss=nan\n",
      "\n",
      "Reg Logistic Ridge Regression, w*=[-2.48795185e+04 -2.98690597e+06 -2.10789439e+06 -2.05823876e+06\n",
      " -5.66270115e+05 -4.73828793e+04 -6.51262965e+06 -2.44429870e+03\n",
      " -5.83182668e+04 -4.94362186e+05 -2.67481449e+06 -4.75047327e+04\n",
      "  2.62497691e+04 -8.75984901e+03 -5.86574899e+05  1.61434013e+02\n",
      " -3.96073657e+02 -1.20970993e+06  5.91581538e+02 -5.78230102e+02\n",
      " -9.84084890e+05  1.18615249e+03 -3.99301836e+06 -1.50692885e+04\n",
      " -1.81488429e+06  7.58831237e+01  2.60573303e+02 -1.44900738e+06\n",
      "  3.17632850e+02 -2.37886919e+02 -8.78589004e+05], loss=nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.01\n",
    "max_iters = 30\n",
    "initial_w = np.zeros(31)\n",
    "lambda_ = 0.00001\n",
    "\n",
    "regression_res = [least_squares_GD(y, tx, initial_w, max_iters,gamma),\n",
    "                  least_squares_SGD(y, tx, initial_w, max_iters, gamma),\n",
    "                  least_squares(y, tx),\n",
    "                  ridge_regression(y,tx,lambda_),\n",
    "                  logistic_regression(y, tx, initial_w, max_iters, gamma),\n",
    "                  reg_logistic_regressions(y, tx, lambda_, initial_w, max_iters, gamma)]\n",
    "regression_names = [\"Gradient Descent\",\"Stochastic Gradient Descent\", \"Least Squares\", \"Ridge Regression1\",'Logistic Ridge Regression','Reg Logistic Ridge Regression']\n",
    "print('-----Without standardization-----')\n",
    "for i in range (len(regression_res)):\n",
    "    w,loss = regression_res[i]\n",
    "    print(\"{name}, w*={w}, loss={l}\\n\".format(name=regression_names[i],w=w, l=loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
