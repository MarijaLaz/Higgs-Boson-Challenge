{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from proj1_helpers import *\n",
    "from preprocessing import *\n",
    "from crossvalidation import *\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,) (250000, 30) (250000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load data\n",
    "DATA_TRAIN_PATH = '../data/train.csv' #download train data and supply path here \n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "#add constant term\n",
    "#tx = np.c_[np.ones((y.shape[0], 1)), x]\n",
    "\n",
    "print(y.shape, x.shape, ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_jet(y, tx):\n",
    "    '''\n",
    "        y -> label data set\n",
    "        tx -> examples data set\n",
    "        Splits data into data sets according to the number of jets\n",
    "        -----\n",
    "        Returns\n",
    "        4 arrays of label data sets for each jet_num\n",
    "        4 arrays of examples data sets for each jet_num\n",
    "        4 arrays of indexes for each jet_num\n",
    "    '''\n",
    "    #features\n",
    "    jet_0_tx = []\n",
    "    jet_1_tx = []\n",
    "    jet_2_tx = []\n",
    "    jet_3_tx = []\n",
    "    #labels\n",
    "    jet_0_y = []\n",
    "    jet_1_y = []\n",
    "    jet_2_y = []\n",
    "    jet_3_y = []\n",
    "    \n",
    "    \n",
    "    index_0 = []\n",
    "    index_1 = []\n",
    "    index_2 = []\n",
    "    index_3 = []\n",
    "\n",
    "    for i in range(tx.shape[0]):\n",
    "        if tx[i,22] == 0:\n",
    "            jet_0_tx.append(tx[i])\n",
    "            jet_0_y.append(y[i])\n",
    "            index_0.append(i)\n",
    "        if tx[i,22] == 1:\n",
    "            jet_1_tx.append(tx[i])\n",
    "            jet_1_y.append(y[i])\n",
    "            index_1.append(i)\n",
    "        if tx[i,22] == 2:\n",
    "            jet_2_tx.append(tx[i])\n",
    "            jet_2_y.append(y[i])\n",
    "            index_2.append(i)\n",
    "        if tx[i,22] == 3:\n",
    "            jet_3_tx.append(tx[i])\n",
    "            jet_3_y.append(y[i])\n",
    "            index_3.append(i)\n",
    "    #removing the column for jet_num which has index 22    \n",
    "    jet_0_tx = np.delete(jet_0_tx, 22, axis=1)\n",
    "    jet_1_tx = np.delete(jet_1_tx, 22, axis=1)\n",
    "    jet_2_tx = np.delete(jet_2_tx, 22, axis=1)\n",
    "    jet_3_tx = np.delete(jet_3_tx, 22, axis=1)\n",
    "    \n",
    "    #removing the PRI_jet_all_pt from jet_0\n",
    "    jet_0_tx = np.delete(jet_0_tx, -1, axis=1)\n",
    "            \n",
    "    return np.array(jet_0_tx), np.array(jet_1_tx), \\\n",
    "           np.array(jet_2_tx), np.array(jet_3_tx), \\\n",
    "           np.array(jet_0_y), np.array(jet_1_y), \\\n",
    "           np.array(jet_2_y), np.array(jet_3_y),\\\n",
    "           np.array(index_0), np.array(index_1),np.array(index_2),np.array(index_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_0_tx, jet_1_tx, jet_2_tx, jet_3_tx, jet_0_y, jet_1_y, jet_2_y, jet_3_y, index_0, index_1, index_2, index_3 = split_jet(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNaN(jet_x):\n",
    "    '''Removes the columns that have nan values for each row'''\n",
    "    return jet_x[:, np.any((jet_x != -999), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_0_tx = removeNaN(jet_0_tx)\n",
    "jet_1_tx = removeNaN(jet_1_tx)\n",
    "#no nan values for jet 2 and jet 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99913, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_0_tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceNaN(jet_x):\n",
    "    '''Replaces the nan values'''\n",
    "    for i in range(jet_x.shape[1]):\n",
    "        idx = jet_x[:,i] > -999\n",
    "        mean = np.mean(jet_x[idx,i])\n",
    "        jet_x[idx==False,i] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceNaN(jet_0_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceNaN(jet_1_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceNaN(jet_2_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceNaN(jet_3_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_0_tx = standardize(jet_0_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_1_tx = standardize(jet_1_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_2_tx = standardize(jet_2_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_3_tx = standardize(jet_3_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_LR = []\n",
    "total_loss_te_LR = []\n",
    "acc_RLR = []\n",
    "total_loss_te_RLR = []\n",
    "\n",
    "gamma = 1e-6\n",
    "max_iters = 2000\n",
    "lambda_ = 0.001\n",
    "k_fold = 5\n",
    "degree = 3\n",
    "\n",
    "jet_0_tx_poly = build_poly(jet_0_tx, degree)\n",
    "initial_w = np.zeros(jet_0_tx_poly.shape[1])\n",
    "\n",
    "k_indices = build_k_indices(jet_0_y, k_fold, 1)\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc, loss_te_LR = cross_validation(jet_0_y, jet_0_tx_poly, k_indices, k, initial_w, 'logistic_regression', max_iters, gamma, lambda_)\n",
    "    acc_LR.append(acc)\n",
    "    total_loss_te_LR.append(loss_te_LR)\n",
    "\n",
    "print(acc_LR)\n",
    "print(total_loss_te_LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99913, 18)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_0_tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
